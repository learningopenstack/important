一致性模型：
  - 弱一致性
    + 最终一致性
      * DNS
      * Gossip(cassandra的通信协议)
  - 强一致性
    + 同步
    + Paxos
    + Raft（multi-paxos)
    + ZAB (multi-paxos)
  
存在的问题：
  - 数据存储在多节点上
  - 分布式系统对fault tolorence的一般解决方案是state machine replication; state machine replication 的共识（consencus）算法
  - paxos其实是一个共识算法，系统的最终一致性，不仅需要达成共识，还会取决于client的行为；

强一致性算法 —————— 主从同步
  - 主从同步复制
    + Master接受写请求
    + Master复制日志到slave
    + Master等待，直到**所有从库**返回
带来的问题：
    - 一个节点失败，Master阻塞，导致整个集群不可用，保证了一致性，可用性却大大降低；
    - ceph写入流程？

强一致性算法 —————— 多数派
  基本想法：
    每次写都保证写入大于N/2个节点，每次读保证大于N/2个节点中读；

带来的问题：
  顺序问题； 节点A，B，C 增加5， 清理0操作； 则与顺序息息相关

Paxos三种：（强一致算法）
  - Basic Paxos
  - Multi paxos
  - fast paxos

Basic Paxos：
角色介绍：
  client： 系统外部角色，请求发起者；
  Propser： 议员； 接受client请求，向集群提出提议（propose），并在冲突发生时，起到冲突调节作用；
  Acceptor：国会，提议投票和接收者；只有形成法定人数（Quorum),提议才会最终被接受；
  Learner： 会议记录员；提议接受，backup备份，对集群一致性没什么影响

潜在问题：活锁(liveness) 或dueling
解决办法： 超时机制；

问题：
  实现难，效率低（2轮rpc），活锁

（升级版本）Multi paxos：
  新概念： leader： 唯一的proposer，所有请求都经过leader

  client        Servers
    |           |   |   |
    X --------> |   |   |  Request
    |           X-->|-->| Prepare(N) leader
    |           |<--X --X Promise(N, I, {Va, Vb})
    |           X ->| ->| Accept!(N, I, Vn)
    |           |<- X --X Accepted(N, I)
    |<----------X   |   | Response
    |           |   |   |  

（再次升级版）Raft
    - 子问题划分：
      + Leader Election
      + Log   Repllication
      + Safety
    - 重定义角色
      + Leader
      + Follower
      + Candidate  //临时状态
//raft动画演示：http://thesecretlivesofdata.com/raft/
//raft官方网站：https://raft.github.io/


（另外的版本）ZAB
    基本与raft相同
     名词定义上的区别：ZAB将某一个leader的周期称为epoch，而raft则成为term
     心跳方向不同：raft心跳leader到follower，ZAB则相反 
